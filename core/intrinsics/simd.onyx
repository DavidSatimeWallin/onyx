package core.intrinsics.simd

#local simd :: package simd

i8x16 :: #type simd.i8x16
i16x8 :: #type simd.i16x8
i32x4 :: #type simd.i32x4
i64x2 :: #type simd.i64x2
f32x4 :: #type simd.f32x4
f64x2 :: #type simd.f64x2
v128  :: #type simd.v128

// NOTE: These u8 values must be compile time known values.
v128_const :: (b1: u8,  b2: u8,  b3: u8,  b4: u8,
                    b5: u8,  b6: u8,  b7: u8,  b8: u8,
                    b9: u8,  b10: u8, b11: u8, b12: u8,
                    b13: u8, b14: u8, b15: u8, b16: u8) -> v128 #intrinsic ---

i8x16_const :: (b1: i8,  b2: i8,  b3: i8,  b4: i8,
                     b5: i8,  b6: i8,  b7: i8,  b8: i8,
                     b9: i8,  b10: i8, b11: i8, b12: i8,
                     b13: i8, b14: i8, b15: i8, b16: i8) -> i8x16 #intrinsic ---
i16x8_const :: (b1: i16,  b2: i16,  b3: i16,  b4: i16,
                     b5: i16,  b6: i16,  b7: i16,  b8: i16) -> i16x8 #intrinsic ---
i32x4_const :: (b1: i32,  b2: i32,  b3: i32,  b4: i32) -> i32x4 #intrinsic ---
i64x2_const :: (b1: i64,  b2: i64)                     -> i64x2 #intrinsic ---
f32x4_const :: (b1: f32,  b2: f32,  b3: f32,  b4: f32) -> f32x4 #intrinsic ---
f64x2_const :: (b1: f64,  b2: f64)                     -> f64x2 #intrinsic ---

// NOTE: These u8 values must be compile time known values.
i8x16_shuffle :: (a: v128, b: v128,
                       b1: u8,  b2: u8,  b3: u8,  b4: u8,
                       b5: u8,  b6: u8,  b7: u8,  b8: u8,
                       b9: u8,  b10: u8, b11: u8, b12: u8,
                       b13: u8, b14: u8, b15: u8, b16: u8) -> v128 #intrinsic ---

i8x16_extract_lane_s :: (v: i8x16, l: u32)           -> i8    #intrinsic ---
i8x16_extract_lane_u :: (v: i8x16, l: u32)           -> u8    #intrinsic ---
i8x16_replace_lane   :: (v: i8x16, l: u32, val: i8)  -> i8x16 #intrinsic ---
i16x8_extract_lane_s :: (v: i16x8, l: u32)           -> i16   #intrinsic ---
i16x8_extract_lane_u :: (v: i16x8, l: u32)           -> u16   #intrinsic ---
i16x8_replace_lane   :: (v: i16x8, l: u32, val: i16) -> i16x8 #intrinsic ---
i32x4_extract_lane   :: (v: i32x4, l: u32)           -> i32   #intrinsic ---
i32x4_replace_lane   :: (v: i32x4, l: u32, val: i32) -> i32x4 #intrinsic ---
i64x2_extract_lane   :: (v: i64x2, l: u32)           -> i64   #intrinsic ---
i64x2_replace_lane   :: (v: i64x2, l: u32, val: i64) -> i64x2 #intrinsic ---
f32x4_extract_lane   :: (v: f32x4, l: u32)           -> f32   #intrinsic ---
f32x4_replace_lane   :: (v: f32x4, l: u32, val: f32) -> f32x4 #intrinsic ---
f64x2_extract_lane   :: (v: f64x2, l: u32)           -> f64   #intrinsic ---
f64x2_replace_lane   :: (v: f64x2, l: u32, val: f64) -> f64x2 #intrinsic ---

i8x16_swizzle :: (v: v128, s: v128)  -> v128  #intrinsic ---
i8x16_splat   :: (val: i8)  -> i8x16 #intrinsic ---
i16x8_splat   :: (val: i16) -> i16x8 #intrinsic ---
i32x4_splat   :: (val: i32) -> i32x4 #intrinsic ---
i64x2_splat   :: (val: i64) -> i64x2 #intrinsic ---
f32x4_splat   :: (val: f32) -> f32x4 #intrinsic ---
f64x2_splat   :: (val: f64) -> f64x2 #intrinsic ---

i8x16_eq   :: (a: i8x16, b: i8x16) -> i8x16 #intrinsic ---
i8x16_neq  :: (a: i8x16, b: i8x16) -> i8x16 #intrinsic ---
i8x16_lt_s :: (a: i8x16, b: i8x16) -> i8x16 #intrinsic ---
i8x16_lt_u :: (a: i8x16, b: i8x16) -> i8x16 #intrinsic ---
i8x16_gt_s :: (a: i8x16, b: i8x16) -> i8x16 #intrinsic ---
i8x16_gt_u :: (a: i8x16, b: i8x16) -> i8x16 #intrinsic ---
i8x16_le_s :: (a: i8x16, b: i8x16) -> i8x16 #intrinsic ---
i8x16_le_u :: (a: i8x16, b: i8x16) -> i8x16 #intrinsic ---
i8x16_ge_s :: (a: i8x16, b: i8x16) -> i8x16 #intrinsic ---
i8x16_ge_u :: (a: i8x16, b: i8x16) -> i8x16 #intrinsic ---

i16x8_eq   :: (a: i16x8, b: i16x8) -> i16x8 #intrinsic ---
i16x8_neq  :: (a: i16x8, b: i16x8) -> i16x8 #intrinsic ---
i16x8_lt_s :: (a: i16x8, b: i16x8) -> i16x8 #intrinsic ---
i16x8_lt_u :: (a: i16x8, b: i16x8) -> i16x8 #intrinsic ---
i16x8_gt_s :: (a: i16x8, b: i16x8) -> i16x8 #intrinsic ---
i16x8_gt_u :: (a: i16x8, b: i16x8) -> i16x8 #intrinsic ---
i16x8_le_s :: (a: i16x8, b: i16x8) -> i16x8 #intrinsic ---
i16x8_le_u :: (a: i16x8, b: i16x8) -> i16x8 #intrinsic ---
i16x8_ge_s :: (a: i16x8, b: i16x8) -> i16x8 #intrinsic ---
i16x8_ge_u :: (a: i16x8, b: i16x8) -> i16x8 #intrinsic ---

i32x4_eq   :: (a: i32x4, b: i32x4) -> i32x4 #intrinsic ---
i32x4_neq  :: (a: i32x4, b: i32x4) -> i32x4 #intrinsic ---
i32x4_lt_s :: (a: i32x4, b: i32x4) -> i32x4 #intrinsic ---
i32x4_lt_u :: (a: i32x4, b: i32x4) -> i32x4 #intrinsic ---
i32x4_gt_s :: (a: i32x4, b: i32x4) -> i32x4 #intrinsic ---
i32x4_gt_u :: (a: i32x4, b: i32x4) -> i32x4 #intrinsic ---
i32x4_le_s :: (a: i32x4, b: i32x4) -> i32x4 #intrinsic ---
i32x4_le_u :: (a: i32x4, b: i32x4) -> i32x4 #intrinsic ---
i32x4_ge_s :: (a: i32x4, b: i32x4) -> i32x4 #intrinsic ---
i32x4_ge_u :: (a: i32x4, b: i32x4) -> i32x4 #intrinsic ---

f32x4_eq  :: (a: f32x4, b: f32x4) -> i32x4 #intrinsic ---
f32x4_neq :: (a: f32x4, b: f32x4) -> i32x4 #intrinsic ---
f32x4_lt  :: (a: f32x4, b: f32x4) -> i32x4 #intrinsic ---
f32x4_gt  :: (a: f32x4, b: f32x4) -> i32x4 #intrinsic ---
f32x4_le  :: (a: f32x4, b: f32x4) -> i32x4 #intrinsic ---
f32x4_ge  :: (a: f32x4, b: f32x4) -> i32x4 #intrinsic ---

f64x2_eq  :: (a: f64x2, b: f64x2) -> f64x2 #intrinsic ---
f64x2_neq :: (a: f64x2, b: f64x2) -> f64x2 #intrinsic ---
f64x2_lt  :: (a: f64x2, b: f64x2) -> f64x2 #intrinsic ---
f64x2_gt  :: (a: f64x2, b: f64x2) -> f64x2 #intrinsic ---
f64x2_le  :: (a: f64x2, b: f64x2) -> f64x2 #intrinsic ---
f64x2_ge  :: (a: f64x2, b: f64x2) -> f64x2 #intrinsic ---

v128_not    :: (v: v128) -> v128 #intrinsic ---
v128_and    :: (a: v128, b: v128) -> v128 #intrinsic ---
v128_andnot :: (a: v128, b: v128) -> v128 #intrinsic ---
v128_or     :: (a: v128, b: v128) -> v128 #intrinsic ---
v128_xor    :: (a: v128, b: v128) -> v128 #intrinsic ---
v128_bitselect :: (a: v128, b: v128, c: v128) -> v128 #intrinsic ---

i8x16_abs            :: (a: i8x16) -> i8x16 #intrinsic ---
i8x16_neg            :: (a: i8x16) -> i8x16 #intrinsic ---
i8x16_any_true       :: (a: i8x16) -> bool #intrinsic ---
i8x16_all_true       :: (a: i8x16) -> bool #intrinsic ---
i8x16_bitmask        :: (a: i8x16, b: i8x16) -> i8x16 #intrinsic ---
i8x16_narrow_i16x8_s :: (a: i16x8) -> i8x16 #intrinsic ---
i8x16_narrow_i16x8_u :: (a: i16x8) -> i8x16 #intrinsic ---
i8x16_shl            :: (a: i8x16, s: i32) -> i8x16 #intrinsic ---
i8x16_shr_s          :: (a: i8x16, s: i32) -> i8x16 #intrinsic ---
i8x16_shr_u          :: (a: i8x16, s: i32) -> i8x16 #intrinsic ---
i8x16_add            :: (a: i8x16, b: i8x16) -> i8x16 #intrinsic ---
i8x16_add_sat_s      :: (a: i8x16, b: i8x16) -> i8x16 #intrinsic ---
i8x16_add_sat_u      :: (a: i8x16, b: i8x16) -> i8x16 #intrinsic ---
i8x16_sub            :: (a: i8x16, b: i8x16) -> i8x16 #intrinsic ---
i8x16_sub_sat_s      :: (a: i8x16, b: i8x16) -> i8x16 #intrinsic ---
i8x16_sub_sat_u      :: (a: i8x16, b: i8x16) -> i8x16 #intrinsic ---
i8x16_min_s          :: (a: i8x16, b: i8x16) -> i8x16 #intrinsic ---
i8x16_min_u          :: (a: i8x16, b: i8x16) -> i8x16 #intrinsic ---
i8x16_max_s          :: (a: i8x16, b: i8x16) -> i8x16 #intrinsic ---
i8x16_max_u          :: (a: i8x16, b: i8x16) -> i8x16 #intrinsic ---
i8x16_avgr_u         :: (a: i8x16) -> i8x16 #intrinsic ---

i16x8_abs                :: (a: i16x8) -> i16x8 #intrinsic ---
i16x8_neg                :: (a: i16x8) -> i16x8 #intrinsic ---
i16x8_any_true           :: (a: i16x8) -> bool #intrinsic ---
i16x8_all_true           :: (a: i16x8) -> bool #intrinsic ---
i16x8_bitmask            :: (a: i16x8, b: i16x8) -> i16x8 #intrinsic ---
i16x8_narrow_i32x4_s     :: (a: i32x4) -> i16x8 #intrinsic ---
i16x8_narrow_i32x4_u     :: (a: i32x4) -> i16x8 #intrinsic ---
i16x8_widen_low_i8x16_s  :: (a: i8x16) -> i16x8 #intrinsic ---
i16x8_widen_high_i8x16_s :: (a: i8x16) -> i16x8 #intrinsic ---
i16x8_widen_low_i8x16_u  :: (a: i8x16) -> i16x8 #intrinsic ---
i16x8_widen_high_i8x16_u :: (a: i8x16) -> i16x8 #intrinsic ---
i16x8_shl                :: (a: i16x8, s: i32) -> i16x8 #intrinsic ---
i16x8_shr_s              :: (a: i16x8, s: i32) -> i16x8 #intrinsic ---
i16x8_shr_u              :: (a: i16x8, s: i32) -> i16x8 #intrinsic ---
i16x8_add                :: (a: i16x8, b: i16x8) -> i16x8 #intrinsic ---
i16x8_add_sat_s          :: (a: i16x8, b: i16x8) -> i16x8 #intrinsic ---
i16x8_add_sat_u          :: (a: i16x8, b: i16x8) -> i16x8 #intrinsic ---
i16x8_sub                :: (a: i16x8, b: i16x8) -> i16x8 #intrinsic ---
i16x8_sub_sat_s          :: (a: i16x8, b: i16x8) -> i16x8 #intrinsic ---
i16x8_sub_sat_u          :: (a: i16x8, b: i16x8) -> i16x8 #intrinsic ---
i16x8_mul                :: (a: i16x8, b: i16x8) -> i16x8 #intrinsic ---
i16x8_min_s              :: (a: i16x8, b: i16x8) -> i16x8 #intrinsic ---
i16x8_min_u              :: (a: i16x8, b: i16x8) -> i16x8 #intrinsic ---
i16x8_max_s              :: (a: i16x8, b: i16x8) -> i16x8 #intrinsic ---
i16x8_max_u              :: (a: i16x8, b: i16x8) -> i16x8 #intrinsic ---
i16x8_avgr_u             :: (a: i16x8) -> i16x8 #intrinsic ---

i32x4_abs                :: (a: i32x4) -> i32x4 #intrinsic ---
i32x4_neg                :: (a: i32x4) -> i32x4 #intrinsic ---
i32x4_any_true           :: (a: i32x4) -> bool #intrinsic ---
i32x4_all_true           :: (a: i32x4) -> bool #intrinsic ---
i32x4_bitmask            :: (a: i32x4, b: i32x4) -> i32x4 #intrinsic ---
i32x4_widen_low_i16x8_s  :: (a: i16x8) -> i32x4 #intrinsic ---
i32x4_widen_high_i16x8_s :: (a: i16x8) -> i32x4 #intrinsic ---
i32x4_widen_low_i16x8_u  :: (a: i16x8) -> i32x4 #intrinsic ---
i32x4_widen_high_i16x8_u :: (a: i16x8) -> i32x4 #intrinsic ---
i32x4_shl                :: (a: i32x4, s: i32) -> i32x4 #intrinsic ---
i32x4_shr_s              :: (a: i32x4, s: i32) -> i32x4 #intrinsic ---
i32x4_shl_u              :: (a: i32x4, s: i32) -> i32x4 #intrinsic ---
i32x4_add                :: (a: i32x4, b: i32x4) -> i32x4 #intrinsic ---
i32x4_sub                :: (a: i32x4, b: i32x4) -> i32x4 #intrinsic ---
i32x4_mul                :: (a: i32x4, b: i32x4) -> i32x4 #intrinsic ---
i32x4_min_s              :: (a: i32x4, b: i32x4) -> i32x4 #intrinsic ---
i32x4_min_u              :: (a: i32x4, b: i32x4) -> i32x4 #intrinsic ---
i32x4_max_s              :: (a: i32x4, b: i32x4) -> i32x4 #intrinsic ---
i32x4_max_u              :: (a: i32x4, b: i32x4) -> i32x4 #intrinsic ---

i64x2_neg   :: (a: i64x2) -> i64x2 #intrinsic ---
i64x2_shl   :: (a: i64x2, s: i32) -> i64x2 #intrinsic ---
i64x2_shr_s :: (a: i64x2, s: i32) -> i64x2 #intrinsic ---
i64x2_shr_u :: (a: i64x2, s: i32) -> i64x2 #intrinsic ---
i64x2_add   :: (a: i64x2, b: i64x2) -> i64x2 #intrinsic ---
i64x2_sub   :: (a: i64x2, b: i64x2) -> i64x2 #intrinsic ---
i64x2_mul   :: (a: i64x2, b: i64x2) -> i64x2 #intrinsic ---

f32x4_abs  :: (a: f32x4) -> f32x4 #intrinsic ---
f32x4_neg  :: (a: f32x4) -> f32x4 #intrinsic ---
f32x4_sqrt :: (a: f32x4) -> f32x4 #intrinsic ---
f32x4_add  :: (a: f32x4, b: f32x4) -> f32x4 #intrinsic ---
f32x4_sub  :: (a: f32x4, b: f32x4) -> f32x4 #intrinsic ---
f32x4_mul  :: (a: f32x4, b: f32x4) -> f32x4 #intrinsic ---
f32x4_div  :: (a: f32x4, b: f32x4) -> f32x4 #intrinsic ---
f32x4_min  :: (a: f32x4, b: f32x4) -> f32x4 #intrinsic ---
f32x4_max  :: (a: f32x4, b: f32x4) -> f32x4 #intrinsic ---

f64x2_abs  :: (a: f64x2) -> f64x2 #intrinsic ---
f64x2_neg  :: (a: f64x2) -> f64x2 #intrinsic ---
f64x2_sqrt :: (a: f64x2) -> f64x2 #intrinsic ---
f64x2_add  :: (a: f64x2, b: f64x2) -> f64x2 #intrinsic ---
f64x2_sub  :: (a: f64x2, b: f64x2) -> f64x2 #intrinsic ---
f64x2_mul  :: (a: f64x2, b: f64x2) -> f64x2 #intrinsic ---
f64x2_div  :: (a: f64x2, b: f64x2) -> f64x2 #intrinsic ---
f64x2_min  :: (a: f64x2, b: f64x2) -> f64x2 #intrinsic ---
f64x2_max  :: (a: f64x2, b: f64x2) -> f64x2 #intrinsic ---

// NOTE: These may be backwards
i32x4_trunc_sat_f32x4_s :: (v: f32x4) -> i32x4 #intrinsic ---
i32x4_trunc_sat_f32x4_u :: (v: f32x4) -> i32x4 #intrinsic ---
f32x4_convert_i32x4_s   :: (v: i32x4) -> f32x4 #intrinsic ---
f32x4_convert_i32x4_u   :: (v: i32x4) -> f32x4 #intrinsic ---
